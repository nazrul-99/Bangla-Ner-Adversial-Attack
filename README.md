# BanglaBERT-Defense: Analyzing Adversarial Attacks in Low-Resource NLP
Welcome to BanglaBERT-Defense—a project for improving NLP security for low-resource languages, especially Bangla. Here, I set out to answer a simple question: How vulnerable are our best Bangla language models to adversarial attacks?

### What’s This About? 
This repo contains my experiments and insights on launching various adversarial attacks against BanglaBERT, a leading transformer model for Bangla NLP. For the evaluation, I used the BanNerd Datase, which is probably the most comprehensive and well-annotated resource for Bangla Named Entity Recognition (NER).

### Why I Did This 
As a researcher working on Bangla NLP, I’ve seen how quickly resources and models are evolving—but also how easily they might be tricked or subverted. If adversarial attacks can fool robust English models, how do our Bangla tools fare?There’s room for improvement, and I want to draw attention to these gaps.

### What You’ll Find Here 
- Attack setups and scripts for Bangla NER using BanNerd
- Results showing which adversarial strategies can “break” BanglaBERT
- Analysis and thoughts on why these issues matter for the Bangla NLP community
- Pointers for possible defenses or next steps for robust model development
